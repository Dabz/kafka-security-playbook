# Basic broker and listener configuration
broker.id=3
listeners=SASL_PLAINTEXT://kafka3.kerberos_default:9093
advertised.listeners=SASL_PLAINTEXT://kafka3.kerberos_default:9093
zookeeper.connect=zookeeper1.kerberos_default:2181
log.dirs=/var/lib/kafka

offsets.topic.replication.factor=2
transaction.state.log.replication.factor=2
transaction.state.log.min.isr=1
num.partitions=12


# Kerberos / GSSAPI Authentication mechanism
sasl.enabled.mechanisms=GSSAPI
sasl.kerberos.service.name=kafka


# Configure replication to require Kerberos:
sasl.mechanism.inter.broker.protocol=GSSAPI
security.inter.broker.protocol=SASL_PLAINTEXT

# Authorization config:
authorizer.class.name=kafka.security.auth.SimpleAclAuthorizer
zookeeper.set.acl=true
allow.everyone.if.no.acl.found=false
super.users=User:admin;User:kafka








##################### Confluent Metrics Reporter #######################
# Confluent Control Center and Confluent Auto Data Balancer integration
#
# Uncomment the following lines to publish monitoring data for
# Confluent Control Center and Confluent Auto Data Balancer
# If you are using a dedicated metrics cluster, also adjust the settings
# to point to your metrics kakfa cluster.
metric.reporters=io.confluent.metrics.reporter.ConfluentMetricsReporter
confluent.metrics.reporter.bootstrap.servers=kafka1.kerberos_default:9093
confluent.metrics.reporter.sasl.mechanism=GSSAPI
confluent.metrics.reporter.security.protocol=SASL_PLAINTEXT
confluent.metrics.reporter.sasl.kerberos.service.name=kafka
#TODO: Review the principal name used here:
confluent.metrics.reporter.sasl.jaas.config=com.sun.security.auth.module.Krb5LoginModule required \
   useKeyTab=true \
   storeKey=true \
   keyTab="/var/lib/secret/kafka1.key" \
   principal="kafka/kafka1.kerberos_default@TEST.CONFLUENT.IO";

#
#
# Uncomment the following line if the metrics cluster has a single broker
confluent.metrics.reporter.topic.replicas=1
confluent.support.metrics.enable=false
confluent.support.customer.id=anonymous
