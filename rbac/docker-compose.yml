version: '3.4'
services:
    ldap:
        image: osixia/openldap:1.3.0
        hostname: ldap
        container_name: ldap
        environment:
            LDAP_ORGANISATION: "Confluent"
            LDAP_DOMAIN: "confluent.io"
        ports:
            - "389:389"
            - "636:636"
        volumes:
            - "$PWD/ldap/custom:/container/service/slapd/assets/config/bootstrap/ldif/custom"
        command: "--copy-service"

    # remember that the user name is CN=admin,OU=confluent,OU=io and the password is admin
    #
    phpldapadmin-service:
        image: osixia/phpldapadmin:0.7.2
        container_name: ldapadmin-service
        environment:
          - PHPLDAPADMIN_LDAP_HOSTS=ldap
        ports:
          - "6444:443"
        depends_on:
          - ldap

    zookeeper:
        image: ${REPOSITORY}/cp-zookeeper:${TAG}
        hostname: zookeeper
        container_name: zookeeper
        ports:
            - "2181:2181"
        environment:
            ZOOKEEPER_CLIENT_PORT: 2181
            ZOOKEEPER_TICK_TIME: 2000
        healthcheck:
            test: nc -z localhost 2181
            interval: 5s
            retries: 5
            start_period: 30s

    kafka:
        image: ${REPOSITORY}/cp-server:${TAG}
        hostname: kafka
        container_name: kafka
        depends_on:
            - zookeeper
            - ldap
        ports:
            - "8090:8090"
            - "9094:9094"
        volumes:
            - ./conf:/tmp/conf
            - ./client-configs:/etc/client-configs
            - ./kafka-registered.sh:/etc/kafka-registered.sh
        healthcheck:
            test: nc -z localhost 8090 && nc -z localhost 9094 && /etc/kafka-registered.sh zookeeper:2181
            interval: 3s
            retries: 15
            start_period: 30s
        environment:
          # ============= CONFIG SHARED BY BROKER AND MDS ===============
          # Setup super.users with unlimited access to cluster
          # for broker it means unlimited access to broker
          # for MDS it means unlimited access to MDS
          # admin is for broker-to-broker communication
          # mds is for MDS to talk to broker
          # alice is an LDAP user - for initial bootstrapping of MDS users
          KAFKA_SUPER_USERS: User:admin;User:mds;User:alice

          # ===================== CONFIGURE BROKER =======================
          # GENERAL CONFIG
          KAFKA_BROKER_ID: 1
          KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
          KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
          KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://schema-registry:8081

          # CONFIGURE LISTENERS
          # RBAC needs separate internal and external listeners
          # OUTSIDE listener is needed if you want to talk to this kafka from your macbook - your macbook is not member of docker network
          # created by compose, so won't know the hostname called 'broker', which will be returned in a list of listeners when console producer or consumer
          # try to get full listener list from bootstrap server
          KAFKA_ADVERTISED_LISTENERS: INTERNAL://localhost:9093,EXTERNAL://kafka:9092,OUTSIDE://localhost:9094
          KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:SASL_PLAINTEXT,EXTERNAL:SASL_PLAINTEXT,OUTSIDE:SASL_PLAINTEXT
          KAFKA_CONFLUENT_METADATA_SECURITY_PROTOCOL: SASL_PLAINTEXT

          # Configure interbroker listener
          KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
          KAFKA_SASL_MECHANISM_INTER_BROKER_PROTOCOL: PLAIN
          KAFKA_LISTENER_NAME_INTERNAL_SASL_ENABLED_MECHANISMS: PLAIN
          # note we're only specifying two users, one for broker-to-broker communication (admin) and one for MDS to talk to broker (mds)
          KAFKA_LISTENER_NAME_INTERNAL_PLAIN_SASL_JAAS_CONFIG: |
                                                              \
                                                              org.apache.kafka.common.security.plain.PlainLoginModule required \
                                                              username="admin" \
                                                              password="admin-secret" \
                                                              user_admin="admin-secret" \
                                                              user_mds="mds-secret";

          # Configure external listener
          KAFKA_LISTENER_NAME_EXTERNAL_SASL_ENABLED_MECHANISMS: OAUTHBEARER
          KAFKA_LISTENER_NAME_EXTERNAL_OAUTHBEARER_SASL_SERVER_CALLBACK_HANDLER_CLASS: io.confluent.kafka.server.plugins.auth.token.TokenBearerValidatorCallbackHandler
          KAFKA_LISTENER_NAME_EXTERNAL_OAUTHBEARER_SASL_LOGIN_CALLBACK_HANDLER_CLASS: io.confluent.kafka.server.plugins.auth.token.TokenBearerServerLoginCallbackHandler
          KAFKA_LISTENER_NAME_EXTERNAL_OAUTHBEARER_SASL_JAAS_CONFIG: |
                                                               \
                                                               org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required \
                                                               publicKeyPath="/tmp/conf/public.pem";

          # Configure outside listener
          KAFKA_LISTENER_NAME_OUTSIDE_SASL_ENABLED_MECHANISMS: PLAIN
          KAFKA_LISTENER_NAME_OUTSIDE_PLAIN_SASL_SERVER_CALLBACK_HANDLER_CLASS: io.confluent.security.auth.provider.ldap.LdapAuthenticateCallbackHandler
          KAFKA_LISTENER_NAME_OUTSIDE_PLAIN_SASL_JAAS_CONFIG: |
                                                      \
                                                      org.apache.kafka.common.security.plain.PlainLoginModule required \
                                                      username="admin" \
                                                      password="admin-secret";
          
          # CONFIGURE AUTHORIZER
          # Setup kafka to use RBAC authorizer
          KAFKA_AUTHORIZER_CLASS_NAME: io.confluent.kafka.security.authorizer.ConfluentServerAuthorizer

          # ======================== CONFIGURE MDS ====================================
          # Configure how MDS talks to broker
          KAFKA_CONFLUENT_METADATA_BOOTSTRAP_SERVERS: INTERNAL://localhost:9093
          KAFKA_CONFLUENT_METADATA_SASL_MECHANISM: PLAIN
          KAFKA_CONFLUENT_METADATA_SASL_JAAS_CONFIG: |
                                                      \
                                                      org.apache.kafka.common.security.plain.PlainLoginModule required \
                                                      username="mds" \
                                                      password="mds-secret";
          # Configure how MDS stores its data in a topic
          # supposedly more stuff can be overridden with the same prefix
          KAFKA_CONFLUENT_METADATA_TOPIC_REPLICATION_FACTOR: 1

          # Configure MDS listener and http server
          KAFKA_CONFLUENT_METADATA_SERVER_AUTHENTICATION_METHOD: BEARER
          KAFKA_CONFLUENT_METADATA_SERVER_LISTENERS: http://0.0.0.0:8090
          KAFKA_CONFLUENT_METADATA_SERVER_ADVERTISED_LISTENERS: http://kafka:8090

          # Configure RBAC token server (authentication)
          KAFKA_CONFLUENT_METADATA_SERVER_TOKEN_AUTH_ENABLE: 'true'
          KAFKA_CONFLUENT_METADATA_SERVER_TOKEN_MAX_LIFETIME_MS: 3600000
          KAFKA_CONFLUENT_METADATA_SERVER_TOKEN_SIGNATURE_ALGORITHM: RS256
          KAFKA_CONFLUENT_METADATA_SERVER_TOKEN_KEY_PATH: /tmp/conf/keypair.pem
          KAFKA_CONFLUENT_METADATA_SERVER_PUBLIC_KEY_PATH: /tmp/conf/public.pem

          # Configure RBAC authorizer
          # KAFKA_CONFLUENT_AUTHORIZER_SCOPE: myCluster
          KAFKA_CONFLUENT_AUTHORIZER_ACCESS_RULE_PROVIDERS: CONFLUENT,ZK_ACL
          # KAFKA_CONFLUENT_AUTHORIZER_METADATA_PROVIDER: RBAC

          # Configure MDS to talk to AD/LDAP
          KAFKA_LDAP_JAVA_NAMING_FACTORY_INITIAL: com.sun.jndi.ldap.LdapCtxFactory
          KAFKA_LDAP_COM_SUN_JNDI_LDAP_READ_TIMEOUT: 3000
          KAFKA_LDAP_JAVA_NAMING_PROVIDER_URL: ldap://ldap:389
          # how to authenticate to LDAP
          KAFKA_LDAP_JAVA_NAMING_SECURITY_PRINCIPAL: cn=admin,dc=confluent,dc=io
          KAFKA_LDAP_JAVA_NAMING_SECURITY_CREDENTIALS: admin
          KAFKA_LDAP_JAVA_NAMING_SECURITY_AUTHENTICATION: simple
          # how to locate users and groups
          KAFKA_LDAP_USER_SEARCH_BASE: ou=users,dc=confluent,dc=io
          KAFKA_LDAP_GROUP_SEARCH_BASE: ou=groups,dc=confluent,dc=io
          KAFKA_LDAP_USER_NAME_ATTRIBUTE: uid
          KAFKA_LDAP_USER_OBJECT_CLASS: inetOrgPerson
          KAFKA_LDAP_USER_MEMBEROF_ATTRIBUTE: ou
          KAFKA_LDAP_GROUP_NAME_ATTRIBUTE: cn
          KAFKA_LDAP_GROUP_OBJECT_CLASS: posixGroup

          # ======================= CONFIGURE METRICS REPORTER =========================
          KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
          CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1

          # point at our 'INTERNAL' listener
          CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: kafka:9093
          # CONFLUENT_METRICS_REPORTER_ZOOKEEPER_CONNECT: zookeeper:2181
          CONFLUENT_METRICS_REPORTER_SECURITY_PROTOCOL: SASL_PLAINTEXT
          CONFLUENT_METRICS_REPORTER_SASL_MECHANISM: PLAIN
          CONFLUENT_METRICS_REPORTER_SASL_JAAS_CONFIG: |
                                                        \
                                                        org.apache.kafka.common.security.plain.PlainLoginModule required \
                                                        username="admin" \
                                                        password="admin-secret";

          # ======================= OTHER BROKER STUFF =================================
          KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
          # KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
          # CONFLUENT_METRICS_ENABLE: 'true'
          # CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'

    schema-registry:
      image: ${REPOSITORY}/cp-schema-registry:${TAG}
      hostname: schema-registry
      container_name: schema-registry
      depends_on:
        - kafka
      ports:
        - "8081:8081"
      volumes:
        - ./conf:/tmp/conf
      healthcheck:
          test: nc -z localhost 8081
          interval: 3s
          retries: 15
          start_period: 30s
      environment:
        CUB_CLASSPATH: '/etc/confluent/docker/docker-utils.jar:/usr/share/java/confluent-security/schema-registry/*:/usr/share/java/schema-registry/*'
        SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
        SCHEMA_REGISTRY_HOST_NAME: schema-registry
        # This is only needed if you don't have a license and would like to test as part of a trial period
        SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: zookeeper:2181

        # configure how to connect to kafka for SR to store its internal info
        SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: kafka:9092
        SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL: SASL_PLAINTEXT
        SCHEMA_REGISTRY_KAFKASTORE_SASL_MECHANISM: OAUTHBEARER
        SCHEMA_REGISTRY_KAFKASTORE_SASL_LOGIN_CALLBACK_HANDLER_CLASS: io.confluent.kafka.clients.plugins.auth.token.TokenUserLoginCallbackHandler
        SCHEMA_REGISTRY_KAFKASTORE_SASL_JAAS_CONFIG: |
                                                      \
                                                      org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required \
                                                      username="barnie" \
                                                      password="barnie-secret" \
                                                      metadataServerUrls="http://kafka:8090";
        SCHEMA_REGISTRY_KAFKASTORE_TOPIC: _schemas
        SCHEMA_REGISTRY_DEBUG: 'true'

        # ======================= RBAC =================================
        SCHEMA_REGISTRY_SCHEMA_REGISTRY_RESOURCE_EXTENSION_CLASS: io.confluent.kafka.schemaregistry.security.SchemaRegistrySecurityResourceExtension
        SCHEMA_REGISTRY_CONFLUENT_SCHEMA_REGISTRY_AUTHORIZER_CLASS: io.confluent.kafka.schemaregistry.security.authorizer.rbac.RbacAuthorizer
        SCHEMA_REGISTRY_REST_SERVLET_INITIALIZOR_CLASSES: io.confluent.common.security.jetty.initializer.InstallBearerOrBasicSecurityHandler
        # how to connect to MDS
        SCHEMA_REGISTRY_CONFLUENT_METADATA_BOOTSTRAP_SERVER_URLS: http://kafka:8090
        SCHEMA_REGISTRY_CONFLUENT_METADATA_HTTP_AUTH_CREDENTIALS_PROVIDER: BASIC
        SCHEMA_REGISTRY_CONFLUENT_METADATA_BASIC_AUTH_USER_INFO: barnie:barnie-secret
        # public key to verify tokens during authentication
        SCHEMA_REGISTRY_PUBLIC_KEY_PATH: /tmp/conf/public.pem

    connect:
      image: ${REPOSITORY}/cp-server-connect:${TAG}
      hostname: connect
      container_name: connect
      depends_on:
        - kafka
      ports:
        - "8083:8083"
      volumes:
        - ./conf:/tmp/conf
      # - ./connect-source:/tmp/connect-source
      #  - ./connect-sink:/tmp/connect-sink
      healthcheck:
          test: nc -z localhost 8083
          interval: 3s
          retries: 20
          start_period: 30s
      environment:
        CUB_CLASSPATH: '/etc/confluent/docker/docker-utils.jar:/usr/share/java/confluent-security/connect/*:/usr/share/java/kafka/*'
        # we can run without zookeeper connect in local environment
        # CONNECT_ZOOKEEPER_CONNECT: 'zookeeper:2181'

        # general settings
        CONNECT_REST_ADVERTISED_HOST_NAME: connect
        CONNECT_REST_PORT: 8083
        CONNECT_GROUP_ID: connect-cluster
        # configs storage topic
        CONNECT_CONFIG_STORAGE_TOPIC: connect-configs
        CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
        # offsets storage topic and settings
        CONNECT_OFFSET_STORAGE_TOPIC: connect-offsets
        CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
        CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
        # status storage topic
        CONNECT_STATUS_STORAGE_TOPIC: connect-status
        CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1

        # Default to Json converters:
        CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
        CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
        CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
        CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter

        # Connect to broker
        CONNECT_BOOTSTRAP_SERVERS: 'kafka:9092'
        CONNECT_SECURITY_PROTOCOL: 'SASL_PLAINTEXT'
        CONNECT_SASL_MECHANISM: 'OAUTHBEARER'
        CONNECT_SASL_LOGIN_CALLBACK_HANDLER_CLASS: 'io.confluent.kafka.clients.plugins.auth.token.TokenUserLoginCallbackHandler'
        CONNECT_SASL_JAAS_CONFIG: |
                                  \
                                  org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required \
                                  username="eva" \
                                  password="eva-secret" \
                                  metadataServerUrls="http://kafka:8090";
        # Allow overriding configs on the connector level
        CONNECT_CONNECTOR_CLIENT_CONFIG_OVERRIDE_POLICY: 'All'
        # Default producer configs
        CONNECT_PRODUCER_SECURITY_PROTOCOL: 'SASL_PLAINTEXT'
        CONNECT_PRODUCER_SASL_MECHANISM: 'OAUTHBEARER'
        CONNECT_PRODUCER_SASL_LOGIN_CALLBACK_HANDLER_CLASS: 'io.confluent.kafka.clients.plugins.auth.token.TokenUserLoginCallbackHandler'
        # Default consumer configs
        CONNECT_CONSUMER_SECURITY_PROTOCOL: 'SASL_PLAINTEXT'
        CONNECT_CONSUMER_SASL_MECHANISM: 'OAUTHBEARER'
        CONNECT_CONSUMER_SASL_LOGIN_CALLBACK_HANDLER_CLASS: 'io.confluent.kafka.clients.plugins.auth.token.TokenUserLoginCallbackHandler'
        # Default admin config
        CONNECT_ADMIN_SECURITY_PROTOCOL: 'SASL_PLAINTEXT'
        CONNECT_ADMIN_SASL_MECHANISM: 'OAUTHBEARER'
        CONNECT_ADMIN_SASL_LOGIN_CALLBACK_HANDLER_CLASS: 'io.confluent.kafka.clients.plugins.auth.token.TokenUserLoginCallbackHandler'
        # Load confluent plugins
        CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components"
        # ============================== RBAC ========================================
        CONNECT_REST_EXTENSION_CLASSES: 'io.confluent.connect.security.ConnectSecurityExtension,io.confluent.connect.secretregistry.ConnectSecretRegistryExtension'
        CONNECT_REST_SERVLET_INITIALIZOR_CLASSES: 'io.confluent.common.security.jetty.initializer.InstallBearerOrBasicSecurityHandler'
        CONNECT_PUBLIC_KEY_PATH: '/tmp/conf/public.pem'
        CONNECT_CONFLUENT_METADATA_BOOTSTRAP_SERVER_URLS: 'http://kafka:8090'
        CONNECT_CONFLUENT_METADATA_BASIC_AUTH_USER_INFO: 'eva:eva-secret'
        CONNECT_CONFLUENT_METADATA_HTTP_AUTH_CREDENTIALS_PROVIDER: 'BASIC'
        # ========================= SECRET REGISTRY ==================================
        CONNECT_CONFIG_PROVIDERS: 'secret'
        CONNECT_CONFIG_PROVIDERS_SECRET_CLASS: 'io.confluent.connect.secretregistry.rbac.config.provider.InternalSecretConfigProvider'
        CONNECT_CONFIG_PROVIDERS_SECRET_PARAM_MASTER_ENCRYPTION_KEY: 'password1234'
        CONNECT_CONFIG_PROVIDERS_SECRET_PARAM_KAFKASTORE_TOPIC: '_secrets'
        CONNECT_CONFIG_PROVIDERS_SECRET_PARAM_KAFKASTORE_BOOTSTRAP_SERVERS: 'kafka:9092'
        CONNECT_CONFIG_PROVIDERS_SECRET_PARAM_KAFKASTORE_SECURITY_PROTOCOL: 'SASL_PLAINTEXT'
        CONNECT_CONFIG_PROVIDERS_SECRET_PARAM_KAFKASTORE_SASL_MECHANISM: 'OAUTHBEARER'
        CONNECT_CONFIG_PROVIDERS_SECRET_PARAM_KAFKASTORE_SASL_LOGIN_CALLBACK_HANDLER_CLASS: 'io.confluent.kafka.clients.plugins.auth.token.TokenUserLoginCallbackHandler'
        CONNECT_CONFIG_PROVIDERS_SECRET_PARAM_KAFKASTORE_SASL_JAAS_CONFIG: |
                                                                            \
                                                                            org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required \
                                                                            username="eva" \
                                                                            password="eva-secret" \
                                                                            metadataServerUrls="http://kafka:8090";

    ksqldb-server:
        image: ${REPOSITORY}/cp-ksqldb-server:${TAG}
        hostname: ksqldb-server
        container_name: ksqldb-server
        depends_on:
            - kafka
            - schema-registry
        ports:
          - "8088:8088"
        volumes:
          - ./conf:/tmp/conf
        healthcheck:
          disable: true
        environment:
          # CUB_CLASSPATH: '/usr/share/java/ksqldb-server/*:/usr/share/java/cp-base-new/*'
          CUB_CLASSPATH: '/usr/share/java/ksqldb-server/*:/usr/share/java/cp-base-new/*'
          KSQL_LOG4J_ROOT_LOGLEVEL: TRACE
          KSQL_BOOTSTRAP_SERVERS: "kafka:9092"
          KSQL_HOST_NAME: ksqldb-server
          KSQL_LISTENERS: "http://0.0.0.0:8088"
          KSQL_CACHE_MAX_BYTES_BUFFERING: 0
          KSQL_KSQL_CONNECT_URL: "http://connect:8083"

          # enable rbac confluent security plugin
          KSQL_KSQL_SECURITY_EXTENSION_CLASS: io.confluent.ksql.security.KsqlConfluentSecurityExtension

          # Enable KSQL OAuth authentication
          KSQL_REST_SERVLET_INITIALIZOR_CLASSES: io.confluent.common.security.jetty.initializer.InstallBearerOrBasicSecurityHandler
          KSQL_WEBSOCKET_SERVLET_INITIALIZOR_CLASSES: io.confluent.common.security.jetty.initializer.InstallBearerOrBasicSecurityHandler
          KSQL_OAUTH_JWT_PUBLIC_KEY_PATH: /tmp/conf/public.pem
          KSQL_CONFLUENT_METADATA_PUBLIC_KEY_PATH: /tmp/conf/public.pem
          KSQL_PUBLIC_KEY_PATH: /tmp/conf/public.pem

          # How to connect to MDS
          KSQL_CONFLUENT_METADATA_BOOTSTRAP_SERVER_URLS: http://kafka:8090
          KSQL_CONFLUENT_METADATA_HTTP_AUTH_CREDENTIALS_PROVIDER: BASIC
          KSQL_CONFLUENT_METADATA_BASIC_AUTH_CREDENTIALS_PROVIDER: USER_INFO
          KSQL_CONFLUENT_METADATA_BASIC_AUTH_USER_INFO: fritz:fritz-secret

          # Credentials for kafka access
          KSQL_SECURITY_PROTOCOL: SASL_PLAINTEXT
          KSQL_SASL_MECHANISM: OAUTHBEARER
          KSQL_SASL_JAAS_CONFIG: |
                                  \
                                  org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required \
                                  username="fritz" \
                                  password="fritz-secret" \
                                  metadataServerUrls="http://kafka:8090";
          KSQL_SASL_LOGIN_CALLBACK_HANDLER_CLASS: io.confluent.kafka.clients.plugins.auth.token.TokenUserLoginCallbackHandler

          KSQL_KSQL_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
          KSQL_KSQL_SCHEMA_REGISTRY_BASIC_AUTH_CREDENTIALS_SOURCE: USER_INFO
          KSQL_KSQL_SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO: fritz:fritz-secret
          # KSQL_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
          # KSQL_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"

    control-center:
      image: ${REPOSITORY}/cp-enterprise-control-center:${TAG}
      hostname: control-center
      container_name: control-center
      depends_on:
        - 'zookeeper'
        - 'kafka'
        - 'ksqldb-server'
        - 'connect'
      ports:
        - "9021:9021"
      volumes:
        - ./conf:/tmp/conf
      environment:
        # CUB CLASSPATH
        CUB_CLASSPATH: '/etc/confluent/docker/docker-utils.jar:/usr/share/java/confluent-control-center/*:/usr/share/java/rest-utils/*:/usr/share/java/confluent-common/*'
        # CUB_CLASSPATH: '/etc/confluent/docker/docker-utils.jar:/usr/share/java/confluent-control-center/*'
        # general settings
        CONTROL_CENTER_BOOTSTRAP_SERVERS: 'kafka:9092'
        CONTROL_CENTER_ZOOKEEPER_CONNECT: 'zookeeper:2181'
        CONTROL_CENTER_REPLICATION_FACTOR: 1
        CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
        CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
        CONFLUENT_METRICS_TOPIC_REPLICATION: 1
        PORT: 9021

        # ========================= other services ==============================
        # connect
        CONTROL_CENTER_CONNECT_CONNECT1_CLUSTER: http://connect:8083

        # ksql
        CONTROL_CENTER_KSQL_KSQL1_URL: http://ksqldb-server:8088
        CONTROL_CENTER_KSQL_KSQL1_ADVERTISED_URL: http://localhost:8088 # access KSQL from the browser
        # schema-registry
        CONTROL_CENTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081

        # ========================= RBAC =================================
        CONTROL_CENTER_REST_AUTHENTICATION_METHOD: BEARER
        PUBLIC_KEY_PATH: /tmp/conf/public.pem

        CONFLUENT_METADATA_BASIC_AUTH_USER_INFO: charlie:charlie-secret
        CONFLUENT_METADATA_BOOTSTRAP_SERVER_URLS: http://kafka:8090

        CONTROL_CENTER_STREAMS_SECURITY_PROTOCOL: SASL_PLAINTEXT
        # The following configs are not required by C3 itself, but are required by cub to be able to connect to kafka to check if its ready
        # Seems like C3 would generate these configs when started, but cub runs before C3 starts, so it doesn't have access to these configs
        CONTROL_CENTER_STREAMS_SASL_MECHANISM: OAUTHBEARER
        CONTROL_CENTER_STREAMS_SASL_LOGIN_CALLBACK_HANDLER_CLASS: io.confluent.kafka.clients.plugins.auth.token.TokenUserLoginCallbackHandler
        CONTROL_CENTER_STREAMS_SASL_JAAS_CONFIG: |
                                                  \
                                                  org.apache.kafka.common.security.oauthbearer.OAuthBearerLoginModule required \
                                                  username="charlie" \
                                                  password="charlie-secret" \
                                                  metadataServerUrls="http://kafka:8090";
